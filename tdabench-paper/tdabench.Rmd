---
title: Comparing R packages for calculation of persistent homology
author:
  - name: Eashwar V. Somasundaram
    affiliation: School of Medicine
    address:
    - Case Western Reserve University
    - Cleveland, OH 44106, United States
    email: eashwar.somasundaram@case.edu
  - name: Shael E. Brown
    affiliation: Department of Quantitative Life Sciences
    address:
    - McGill University
    - Montreal, QC H3A 0G4, Canada
    email: shael.brown@mail.mcgill.ca
  - name: Adam Litzler
    affiliation: Department of Translational Hematology and Oncology Research
    address:
    - Cleveland Clinic Foundation
    - Cleveland, OH 44195, United States
    email:  adli4611@colorado.edu
  - name: Jacob G. Scott
    affiliation: Department of Translational Hematology and Oncology Research
    address:
    - Cleveland Clinic Foundation
    - Cleveland, OH 44195, United States
    email: ScottJ10@ccf.org
  - name: Raoul R. Wadhwa
    affiliation: Cleveland Clinic Lerner College of Medicine
    address:
    - Case Western Reserve University
    - Cleveland, OH 44195, United States
    email: raoul.wadhwa@case.edu
abstract: >
  Several persistent homology software libraries have been implemented in R. The Dionysus (TDA), GUDHI (TDA), and Ripser C++ libraries (TDAstats) provide Rips complex functionality. GUDHI  (TDA package) also provides Alpha complex functionality. These software represent powerful analysis tools but are limited computationally. These limitations and guidelines for which persistent homology libraries to use have not been specified in R. We benchmarked the all libraries on a High-Powered Cluster for runtime. We also compared Alpha and Rips for memory burden. Alpha complexes run significantly faster than all Rips complex libraries for all data sets for data dimension less than or equal to three. Alpha complexes were not computable for data dimension greater than 3. TDAstats had the fastest runtimes for all Rips complexes. We recommend performing persistent homology with GUDHI Alpha complexes for data dimension less than or equal to three. For higher dimension, we recommend TDAstats Rips Complex. 
output:
  rticles::rjournal_article:
    includes:
      in_header: preamble.tex
---


\section{Introduction}
Topological data analysis (TDA) is a broad set of methodologies that characterize structural features of data sets inspired by topological principles.
Within the umbrella of TDA, persistent homology represents an algebraic approach to understanding the number, characteristics, and persistence of structural features in an n-dimensional point cloud.

In the basic workflow of persistent homology, a series of simplicial complexes are generated on point clouds to characterize the topological features. 
Simplicial complexes are connected sets of points, lines, and n-dimensional shapes.
There are several methods to generate these complexes on point clouds. 
In this paper, we are using the Rips and Alpha complex for our persistent homology calculations. 
In both methods, a series of data structures, called simplicial complexes, are built on top of a point cloud.
These complexes can be viewed as approximating real topologic relationships in the data.
The exact method of constructing these complexes is described in the Mathematics section. 
However, the key takeaway is that the simplicial complex attempts to reveal the underlying topology of the point cloud. 
These features can be described by dimension and "persistence." 
Long lasting (persistent) features that exist across the series of simplicial complexes intuitively represent "real" geometrical patterns as opposed to noise.

One limitation of persistent homology is its run time limits for processing large numbers of points ( $> 10^9$ points) and calculating of high dimensional features ($>$ 2 dimensions). 
Alpha complex calculations have a complexity of $O(n^\frac{d}{2})$ and Rips complex calculations have a complexity of $O(2^n)$ where n is the number of points and d is the dimension of the point cloud \citep{roadmap}. The limits and computational resources needed to run complex data sets with major persistent homology C++ software have been well characterized \cite{roadmap}.

There are several C++ libraries that calculate Alpha and Rips complexes.
Dionysus provides Alpha and Rips complex functionality \cite{Dionysus}.
GUDHI is another C++ library that also provides both functionalities as well as other TDA methodologies \cite{gudhi}. These libraries have been implemented in R with the TDA package \cite{TDA} providing an easier interface to utilize persistent homology calculations.

A new C++ library, Ripser, was developed as a more efficient way to calculate Rips complexes. The code is supposed to outperform other similar libraries (e.g. Dionysus and GUDHI) by a factor over 40 in runtime \cite{Ripser}. 
This library was given an R interface in the package TDAstats \cite{TDAstats}. 
TDAstats represents a more specialized package for topological data analysis compared to the TDA package.
It calculates persistent homology using the more efficient Ripser algorithm and provides data visualization with integration of ggplot. While Ripser is known to be faster than the other libraries for Rips complex calculations in C++, how this translates in the R interface is not clear.
While C++ generally runs faster than R, R provides higher level functionality, and appeals to a broad audience of data science users.

Topological data analysis has had a broad range of usage from viral evolution to physical chemistry\cite{TDA-Viral,TDA-PChem}. 
Given that persistent homology can apply to any n-dimensional data set, it has wide ranging applicability. 
Its main limiting factor is computational for calculating high dimensional features in large multi-dimensional data sets. 
We believe lack of analysis of these higher dimensional features may under utilize persistent homology's analysis potential.
In this project, we explore different methodologies to find efficient options that could solve this issue. 
We specifically aim to characterize the computational performance (run time) and limits of persistent homology calculations between Rips complexes in the R packages TDAstats and TDA.
We also explore the differences in computational performance between Rips and Alpha complexes in R to assess which datasets are most appropriate for each algorithm.

\section{Mathematics of Persistent Homology}
This section summarizes the mathematics behind generating simplicial complexes on point clouds in the workflow of persistent homology. 
An n-dimensional simplex is the convex hull of n+1 vertices.
More intuitively, n-dimensional simplex is the simplest n-dimensional object (e.g. a 1 simplex is a line, a 2-simplex is a triangle, 3-simplex is a tetrahedron, etc.).
These simplices can be glued together on a common subsimplices to form a simplicial complex (e.g. two triangles sharing a common side).
In a simplicial complex, certain features will arise that can be characterized by dimension number (Betti number): 0-dimensional features refer to connected components, 1-dimensional features refer to holes, 2-dimensional features refer to cavities, etc. \cite{phom-survey}

There are several different methods to construct a simplicial complex on a given point cloud S, but this paper focuses on the Rips and Alpha complexes. 
The Rips complex is perhaps the most common method for constructing a simplicial complex under persistent homology \cite{Rips-Complex}.
In a point cloud of k points, a distance parameter, $\delta$, can be used to draw a circle of diameter $\delta$ around every single point in S.
If the distance parameter is non-zero, then some of the resulting circles may intersect.
If they intersect, a line is drawn to connect the points (which represent the centers of the growing circles).
This group of points and lines form a simplicial complex.
For each distance parameter, $\delta$, there will be some simplicial complex associated with it.
As $\delta$ increases, different topological features may appear, persist, then disappear once $\delta$ has reached a threshold.
Eventually, once $\delta$ reaches the maximum euclidean distance between any pair of points in the point cloud, a convex hull will form around all k points creating a (k-1)-dimensional simplex.
At this stage, all features should have disappeared.
A three column matrix can be created recording the Betti number of a certain feature, the distance, $\delta$, at which that feature appeared, and the $\delta$ at which that feature disappeared.
This matrix characterizes the persistent homology of that point cloud. 

\begin{figure}
  \centering
  \includegraphics[height=2.5in]{../Figures/Final_Figures/Intro_Rips.png}
  \caption{Basic Visualization of the Rips Complex. For a given parameter, $\delta$, $\delta$ diameter circles are drawn around each point. If two circles intersect, a point is drawn between their centers. As $\delta$ continues to grow, more circles intersect filling out the simplicial complex. Features on the simplicial complex appear and die as $\delta$ increases. These features' dimensions, birth, and death are recorded in an n x 3 matrix. Eventually, the full convex hull is drawn ending the "filtration" process.}
\end{figure}

Alpha complexes provide another method to generate simplicial complexes on the point cloud S.
Alpha complexes are closely linked with Voronoi diagrams and Delaunay triangulations.
The Voronoi diagram gives each point in S a cell such that each every point in the cell is closest to that point in S.
The nerve of a Voronoi diagram is equivalent to the Delaunay Triangulation\cite{alpha-complex}.
Alpha complexes are simplicial complexes that are subsets of the Delaunay Triangulation.
The parameter, $\alpha$, can describe the radius of a ball of each point in the point cloud S much like $\delta$ describes the diameter of a circle in the Rips complex.
An Alpha complex at radius $\alpha$ is formed through connecting centers of intersecting regions formed by intersecting the union of $\alpha$ radius balls and the Voronoi diagram. 
Eventually, once $\alpha$ is large enough, the full Delaunay Triangulation is formed.
In between these stages, the birth and death of features at certain values of $\alpha$ can be captured in a three column persistent homology matrix much like the Rips complex.

In both methods, the boundary matrix records all simplicial complexes for a given parameter value. 
From this matrix, the persistent homology matrix is calculated. 
The size of the boundary matrix can describe the memory complexity on the RAM for persistent homology calculations. 
We compare this memory complexity between Alpha and Rips complexes for this project. 

\begin{figure}
  \centering
  \includegraphics[height=1.5in]{../Figures/Final_Figures/Intro_Alpha.png}
  \caption{Basic visualization of the Alpha complex. For a given $\alpha$, $\alpha$ radius balls are drawn around each point, and the union is taken. Then an intersection between this union of $\alpha$ balls and the Vornoi diagram is taken. A connecting segment is drawn between points in adjacent voronoi cells once the $\alpha$ ball "fills" out the Voronoi diagram. As $\alpha$ continues to grow, more circles fill out the Voronoi cells. Eventually, once $\alpha$ is large enough, the Delaunay Triangulation is formed.}
\end{figure}

\section{Methods}
<!--An exclusively R (v3.6.2) code pipeline was built for this project \citep{Rlang,ihaka1996}.-->
We use \CRANpkg{readr} v1.3.1 to read rectangular data \citep{readr}, \CRANpkg{ggplot2} v3.2.1 \citep{ggplot2}, \CRANpkg{scatterplot3d} v0.3-41 \citep{scatterplot3d}, \CRANpkg{recexcavAAR} v0.3.0 \citep{recexcavAAR}, and \CRANpkg{magick} v2.2 \citep{magick} to visualize data, \CRANpkg{bench} v1.0.4 to collect benchmark data \citep{bench}, \CRANpkg{TDA} v1.6.9 \citep{TDA} and \CRANpkg{TDAstats} v0.4.1 \citep{TDAstats} to calculate persistent homology of Vietoris-Rips and alpha simplicial complices, and \CRANpkg{pryr} v0.1.4 for calculations involving R objects \citep{pryr}.
Runtime calculations were averaged over 10 iterations and are visualized as mean $\pm$ SD.
Datasets were generated by sampling functions in base R to generate points uniformly distributed over circles (dimension = 2), spheres (dimension = 3), filled squares (dimension = 2), filled cubes (dimension = 3, 4), and tori (dimension = 3).
The number of points per point cloud varied from 25 to 500 along intervals of 25 points, which were empiric limits chosen after considering available computational resources.
For consistency between software libraries, the minimum and maximum simplicial complex radii were predetermined for each point cloud and provided as parameters to the \CRANpkg{TDA} and \CRANpkg{TDAstats} packages.
Within the \CRANpkg{TDA} package, benchmark data was collected for the GUDHI \citep{gudhi} and Dionysus \citep{Dionysus} libraries; within the \CRANpkg{TDAstats} package, benchmark data was collected for the Ripser \citep{Ripser} library.
As alpha complex calculation was only implemented in GUDHI, alpha complex benchmark data was naturally only collected for the single library.
Measuring memory usage proved challenging since all the libraries calculating persistent homology were implemented in either C++ or Java and then wrapped in R as part of a CRAN package.
Thus, memory burden was indirectly measured by using boundary matrix size as a proxy.
Given that Ripser optimizes computation of persistent homology by avoiding calculation of a boundary matrix, memory use benchmarks are not provided for Ripser and, consequently, \CRANpkg{TDAstats}.

Benchmark data was collected twice - once on a local machine and once on a remote computing node, each of which featured 16 GB random access memory.
Both datasets were compared for consistency and are publicly available at the repository linked below.
Data from the remote computing node is visualized in this report.
The larger point clouds required more than 16 GB of RAM to calculate persistent homology using a subset of the libraries; attempts to compute results resulted in runtime errors, and the corresponding output is missing from the corresponding figures and tables.
Fully reproducible code for all numerical results and figures in this report can be found at https://github.com/eashwarsoma/TDA-benchmark.

\section{Results}

Computing persistent homology of a canonical torus grants quick insight into efficiency of each library (Figure \ref{fig:tor}).
Dionysus exhibits the longest average runtime, and, although Ripser and GUDHI have similar runtimes for smaller point clouds, as the number of points increases Ripser eventually has a significant lead.

\begin{figure}
  \centering
  \includegraphics[height=2.5in]{../Figures/Final_Figures/fig1.png}
  \caption{Comparison of Rips complex persistent homology calculation runtimes across R packages for a torus. The x-axis represents the number of points in a 3D torus point cloud, and y-axis represents average run time. Each library that calculated the Rips complex is differentiated by point color. All calculations calculated up to two dimensional features. Average runtime is presented as mean +/- standard deviation over 10 iterations. ALl three Rips libraries exhibit a polynomial time growth for these parameters. Further details about regression parameters is found in supplemental material on the paper Github. Some libraries are not calculated for all points due to computational limitations, which are described more in the Computational Limitations section.}
\label{fig:tor}
\end{figure}

\subsubsection{Runtime as a function of data dimension (feature = n - 1)}
For small point cloud numbers, Gudhi and TDAstats performed similarly while Dionysus lagged behind. 
At larger point clouds, TDAstats outperforms Gudhi, and the difference among the Rips libraries is more visible.
This result is especially true for calculating higher feature dimensions on large point clouds. 
While the runtime values changed for each point cloud condition, the growth pattern with respect to increasing number of points was similar for all Rips complex libraries. 
For the conditions tested in our analysis, all Rips libraries resulted in an apparent polynomial growth for run time. 
The exact values for the log-log regression of this growth pattern is provided in supplemental data on the paper Github. 

Each panel in figure \ref{fig:cir} corresponds to an n-dimensional circle (circle, sphere, and hypersphere). 
For each point cloud, n-1 dimensional features were calculated.
As the sphere dimensions and feature dimensions increased, the polynomial time growth becomes apparent sooner. 
At these higher dimensional features, some of the curves seem to cut off. 
This is due to certain point cloud sizes not being computable on our devices. 
These limitations are laid out in the "Computation Limits" section.

\begin{widefigure}
  \centering
  \includegraphics[height=2in]{../Figures/Final_Figures/fig2.png}
  \caption{Runtime of persistent homology calculation as a function of underlying engine for different dimension circles. The x-axis represents the number of points in the point cloud, and y-axis represents average run time. Each library that calculated the Rips complex is differentiated by point color. All calculations calculated up to two dimensional features.Panel 1. Comparing persistent homology calculation run times for a 2D circle. Panel 2. Comparing persistent homology calculation run times for a 3D sphere. Panel 3. Comparing persistent homology calculation run times for a 4D hypersphere. Maximum feature dimensions were calculated for each point cloud. Average runtime is presented as mean +/- standard deviation over 10 iterations.}
\label{fig:cir}
\end{widefigure}


\subsubsection{Runtime as a function of feature dimension}
For an n-dimensional point cloud, up to n-1 feature dimensions can be calculated. 
In the field, most work has only included calculations up to 1 or 2 feature dimensions. 
Perhaps this is due to difficulty of conceptualizing what high dimensional features represent. 
However, it might also be due to computational restrictions of calculating high dimensional features. 
For Figure \ref{fig:box}, we restricted the calculations to very small point clouds due to computational limits.  

As feature dimension increased, Rips complexes show a significant rise in run time with increasing feature dimension within an 8 dimensional point cloud. 
With this small sample set, it is not clear whether the growth is exponential or polynomial, so no regression values are provided in the supplement. 

\begin{widefigure}
  \centering
  \includegraphics[height=2in]{../Figures/Final_Figures/fig3.png}
  \caption{Comparison of Rips complex persistent homology calculation as a function of feature dimension. The x-axis represents the number of features in the point cloud, and y-axis represents average run time. Point cloud number was held constant and indicated by color. All Rips complexes were calculated on an 8 dimensional box. Panel 1. Comparing run times for TDAstats. Panel 2. Comparing run times for Dionysus. Panel 3. Comparing run times for GUDHI. Limited point clouds were tested for high dimensional features due to computational limits. Average runtime is presented as mean +/- standard deviation over 10 iterations.}
\label{fig:box}
\end{widefigure}

\subsection{Comparison of alpha and Vietoris-Rips complexes within GUDHI}
The GUDHI library provided functionality to calculate persistent homology with Rips and Alpha complexes. 
Therefore, we only used the GUDHI library to compare performance between Rips and Alpha complexes. 

\subsubsection{Runtime as a function of data dimension (const feature)}
In our study, our computers could not calculate persistent homology for Alpha complexes when the point cloud dimension exceeded 3. 
This is understandable as Alpha complex theoretical complexity increases exponentially for increasing point cloud dimension. 

Changes in computational performance from changing point cloud dimension is one major difference between calculation of Rips and Alpha complexes. This difference can be seen when comparing run times as a function of changing point cloud dimension. 
In figure \ref{fig:ann}, we show that Rips complexes  run time does not change for different dimensional point clouds as long as feature dimension is held constant. Even though Alpha complexes perform better overall, their computation time increases with increasing point cloud dimension even when calculating the same feature dimension. 

Another key difference is that Alpha complex runtime seems to have an apparent linear rise in the conditions for our analysis. 
We provide the linear regression coefficients in the supplemental data on the paper Github. 

\begin{figure}
  \centering
  \includegraphics[height=2in]{../Figures/Final_Figures/fig4.png}
  \caption{Comparing homology calculation as a function of point cloud dimension for Rips vs Alpha complexes. The x-axis represents the number of points in the point cloud, and y-axis represents average run time. Different dimensional annulus point clouds are indicaed by color. Panel 1 = Comparing run times using GUDHI's Rips complex library. Panel 2 = Comparing run times using GUDHI's Alpha complex library. In all calculations, only 1 dimensional features were calculated. For our parameters, Alpha complex run times are more linear in contrast to Rips more polynomial run times. Exact regression data is provided in supplemental material on the paper Github. Average runtime is presented as mean +/- standard deviation over 10 iterations.}
\label{fig:ann}
\end{figure}

\subsubsection{Memory Benchmarks}
As point cloud number increases, Rips complexes show a more dramatic rise in run time than Alpha complexes. 
This is predicted by Rips theoretical exponential complexity and Alpha complex's theoretical polynomial complexity. 
In both complexes, the boundary matrix is used to calculate persistent homology (explained in detail in the Mathematics section). 
The library GUDHI provides functions to return the boundary matrix, which allows us to measure object size. 

Rips complexes show a rapid growth in object size as the point cloud number increases in figure \label{fig:mem1}. 
The growth pattern differences mirror our findings for run time growth with increasing point cloud size. 
Alpha complexes show a linear growth in memory complexity whereas Rips complexes show a polynomial growth. 
However, calculating the object size reveals some interesting differences in what parameters determine the object size of Rips vs Alpha complexes. 

Figure \label{fig:mem2}, panel 2 shows that Alpha complex object size depends on the feature dimension, point cloud size, and point cloud shape with torus and uniform shapes having the higher object size. Noisier shapes like the box and annulus increase object size compared to more uniform shapes like the sphere. 
Figure \label{fig:mem2}, panel 1 shows that Rips complex object size depends only on the point cloud size and feature dimensions. 

\begin{figure}
  \centering
  \includegraphics[height=2.5in]{../Figures/Final_Figures/fig5a.png}
  \caption{Persistent Homology Boundary Matrix for Rips vs Alpha complex. The x-axis represents the number of points in the point cloud, and y-axis represents object size. The type of complex is indicated by color. Maximum feature dimensions were calculated. Panel 1 = Comparing object size on 3D annulus. Panel 2 = Comparing object size on sphere. Panel 3 = Comparing object size on torus. Panel 4 = Comparing object size on 3D box. Similar to runtime growth, Alpha complex showed a linear pattern and Rips complex showed a log-log linear pattern. Regression results can be found in supplemental data on the paper Github}
\label{fig:mem1}
\end{figure}

\begin{widefigure}
  \centering
  \includegraphics[height=2.5in]{../Figures/Final_Figures/fig5t.png}
  \caption{Different factors change boundary matrix size for each complex. The x-axis represents the number of points in the point cloud, and y-axis represents object size. Panel 1 = Rips complex object size depends on feature size and point cloud number alone. For Rips complex, the decreasing number of data points for each calculated feature dimension reflects the computational limits of large point cloud sizes. Point cloud shape is not defined as it had no impact on boundary matrix size. Panel 2 = Alpha complex object size depends on feature size, point cloud number, and point cloud shape. Point cloud shape was indicated as it impacted object size.}
\label{fig:mem2}
\end{widefigure}

\subsubsection{Computational Limitations (advice/guidance for users)}
In benchmarking all of our parameters, each point cloud was given up to 16 GB of RAM. 
However, memory allocation errors as reported by R caused several of our parameters to not run. 
This table describes the point cloud size limit for calculating a given feature dimension. 
Notably, TDAstats has a higher threshold for point cloud size at high dimensions when compared to TDA's GUDHI or Dionysus libraries. 
Alpha complex's limitation is better described as the point cloud dimension being the limiting factor, which is why 3 and 4 dimensional features were not computable.

\begin{table}
\centering
\small
\begin{tabular}{|c|c|c|c|c|}
\hline
Feature & TDA Stats & Dionysus & Gudhi Rips & Gudhi Alpha \\
Dimension & Point Cloud Limit & Point Cloud Limit & Point Cloud Limit & Point Cloud Limit\\
\hline
1 & Not Reached & Not Reached & Not Reached & Not Reached \\ 
2 & Not Reached & 200 points & 280 points & Not Reached \\ 
3 & 300 points & 100 points & 125 points & Could Not Compute \\
4 & 100 points & 50 points & 75 points & Could Not Compute \\ 
\hline
\end{tabular}
\caption{During the benchmarking, certain libraries were not able to calculate persistent homology for sufficiently complex point clouds. 
Limiting factors were point cloud number and feature dimension calculation. 
For Rips complexes, TDA stats had the highest performing capacity among the three Rips libraries. 
Alpha complexes were not computable for any point cloud greater than 3 dimensions, so dimensional features 3 and higher could not be computed.}
\end{table}

\section{Discussion}
As persistent homology calculations continue to become a more popular tool to analyze complex multidimensional data, it will be important to understand from a computational perspective which method to use. 
In this paper, we examined two forms of persistent homology complexes: Vietoris Rips and Alpha complexes. 
Both algorithms describe the topological features through the generation of simplicial complexes. 
The advantage in saving computational time in choosing a particular algorithm depends on the point cloud characteristics.

Figure \ref{fig:fin} shows that at high point cloud sizes, GUDHIâ€™s Alpha complex calculations outperforms TDAstats. 
Theoritically, Alpha complexes gain polynomial complexity as the number of points increases whereas Rips complexes gain exponentially. 
Specifically, Alpha complexes are $O(n^\frac{d}{2})$ and Rips complexes are $O(2^n)$ where n is the number of points on a point cloud and d is the dimensions on the point cloud. 
For the conditions in our paper, Rips and Alpha complexes both performed better than their theoritical maximums. 
Rips complex calculations consistently had a polynomial growth for both runtime and boundary matrix size while Alpha complexes had linear growth.  

Based on this theoretical complexity and our results, Alpha complexes are superior for small dimensional point clouds (3 dimensions and below). 
This advantage becomes especially clear at high number of points.
However, with out computational resources, Alpha complexes were not usable for point cloud dimensions greater than 3. 
If data is more than three dimensions, then it should be dimensionally reduced by a procedure such as PCA for before using Alpha complexes. 

However, if data dimension cannot be reduced, then Rips complexes should be used. Among the different libraries, TDAstats has the fastest calculation time. 
GUDHI and Dionysus significantly fall behind for high feature dimension calculations and high numbers of points. 
GUDHI and Dionysus libraries, however, do have the option of returning the boundary matrix, which Ripser does not do as one of its time saving features. 

\begin{figure}
  \centering
  \includegraphics[height=2.5in]{../Figures/Final_Figures/fig6.png}
  \caption{TDAstats Rips complexes vs GUDHI Alpha complex average run times across all 3D shapes for 2D features. The x-axis represents the number of points in the point cloud, and y-axis represents average run time. The type of complex is indicated by color. Panel 1 = Execution time on annulus. Panel 2 = Execution time on sphere. Panel 3 = Execution time on torus. Panel 4 = Execution time on uniform box. Data is presented as mean +/- standard deviation}
\label{fig:fin}
\end{figure}

While Rips complexes can handle high dimensional data well, it still significantly slows down when looking for higher dimensional topological features. 
The size of the boundary matrix rapidly increases and saturates the RAM even for small numbers of points (e.g. ~100 points when looking for 4 dimensional features). 
Looking for high dimensional features in a large high dimensional point cloud remains a challenge. 
Other persistent homology complex methods exist such as the Delaunay complex, Witness complex, etc. but they are not currently implemented in R [cite]. 
Future challenges would be creating and implementing algorithms that reduce the computational complexity of higher dimensional topological feature calculations for R. 

\begin{figure}
  \centering
  \includegraphics[height=2.5in]{decision.png}
    \caption{Basic decision chart for choosing TDA library based on dataset.}
\label{decision}
\end{figure}

\section{Acknowledgements}
Emily Dolson, PhD for assistance in using the HPC for collecting data

\bibliography{tdabench}


