---
title: Comparing R packages for calculation of persistent homology
author:
  - name: Eashwar V. Somasundaram
    affiliation: School of Medicine
    address:
    - Case Western Reserve University
    - Cleveland, OH 44106, United States
    email: eashwar.somasundaram@case.edu
  - name: Shael E. Brown
    affiliation: Department of Quantitative Life Sciences
    address:
    - McGill University
    - Montreal, QC H3A 0G4, Canada
    email: shael.brown@mail.mcgill.ca
  - name: Adam Litzler
    affiliation: Department of Translational Hematology and Oncology Research
    address:
    - Cleveland Clinic Foundation
    - Cleveland, OH 44195, United States
    email:  adli4611@colorado.edu
  - name: Jacob G. Scott
    affiliation: Department of Translational Hematology and Oncology Research
    address:
    - Cleveland Clinic Foundation
    - Cleveland, OH 44195, United States
    email: ScottJ10@ccf.org
  - name: Raoul R. Wadhwa
    affiliation: Cleveland Clinic Lerner College of Medicine
    address:
    - Case Western Reserve University
    - Cleveland, OH 44195, United States
    email: raoul.wadhwa@case.edu
abstract: >
  Several persistent homology software libraries have been implemented in R. The Dionysus (TDA), GUDHI (TDA), and Ripser C++ libraries (TDAstats) provide Vietoris-Rips complex functionality. GUDHI  (TDA package) also provides alpha complex functionality. These software represent powerful analysis tools but are limited computationally. These limitations and guidelines for which persistent homology libraries to use have not been specified in R. We benchmarked the all libraries on a High-Powered Cluster for runtime. We also compared alpha and Vietoris-Rips for memory burden. Alpha complexes run significantly faster than all Vietoris-Rips complex libraries for all data sets for data dimension less than or equal to three. Alpha complexes were not computable for data dimension greater than 3. TDAstats had the fastest runtimes for all Vietoris-Rips complexes. We recommend performing persistent homology with GUDHI alpha complexes for data dimension less than or equal to three. For higher dimension, we recommend TDAstats Vietoris-Rips Complex. 
output:
  rticles::rjournal_article:
    includes:
      in_header: preamble.tex
---

\section{Introduction}

Topological data analysis (TDA) is a broad set of methodologies that characterize structural features of data sets inspired by topological principles.
Within the umbrella of TDA, persistent homology represents an algebraic approach to understanding the number, characteristics, and persistence of structural features in an n-dimensional point cloud.

In the basic workflow of persistent homology, a series of simplicial complexes are generated on point clouds to characterize the topological features. 
Simplicial complexes are connected sets of points, lines, and n-dimensional shapes.
There are several methods to generate these complexes on point clouds. 
In this paper, we are using the Vietoris-Rips and alpha complex for our persistent homology calculations. 
In both methods, a series of data structures, called simplicial complexes, are built on top of a point cloud.
These complexes can be viewed as approximating real topologic relationships in the data.
The exact method of constructing these complexes is described in the Mathematics section. 
However, the key takeaway is that the simplicial complex attempts to reveal the underlying topology of the point cloud. 
These features can be described by dimension and "persistence." 
Long lasting (persistent) features that exist across the series of simplicial complexes intuitively represent "real" geometrical patterns as opposed to noise.

One limitation of persistent homology is its run time limits for processing large numbers of points ( $> 10^9$ points) and calculating of high dimensional features ($>$ 2 dimensions). 
Alpha complex calculations have a complexity of $O(n^\frac{d}{2})$ and Vietoris-Rips complex calculations have a complexity of $O(2^n)$ where n is the number of points and d is the dimension of the point cloud \citep{roadmap}. The limits and computational resources needed to run complex data sets with major persistent homology C++ software have been well characterized \cite{roadmap}.

There are several C++ libraries that calculate alpha and Vietoris-Rips complexes.
Dionysus provides alpha and Vietoris-Rips complex functionality \cite{Dionysus}.
GUDHI is another C++ library that also provides both functionalities as well as other TDA methodologies \cite{gudhi}. These libraries have been implemented in R with the TDA package \cite{TDA} providing an easier interface to utilize persistent homology calculations.

A new C++ library, Ripser, was developed as a more efficient way to calculate Vietoris-Rips complexes. The code is supposed to outperform other similar libraries (e.g. Dionysus and GUDHI) by a factor over 40 in runtime \cite{Ripser}. 
This library was given an R interface in the package TDAstats \cite{TDAstats}. 
TDAstats represents a more specialized package for topological data analysis compared to the TDA package.
It calculates persistent homology using the more efficient Ripser algorithm and provides data visualization with integration of ggplot. While Ripser is known to be faster than the other libraries for Vietoris-Rips complex calculations in C++, how this translates in the R interface is not clear.
While C++ generally runs faster than R, R provides higher level functionality, and appeals to a broad audience of data science users.

Topological data analysis has had a broad range of usage from viral evolution to physical chemistry\cite{TDA-Viral,TDA-PChem}. 
Given that persistent homology can apply to any n-dimensional data set, it has wide ranging applicability. 
Its main limiting factor is computational for calculating high dimensional features in large multi-dimensional data sets. 
We believe lack of analysis of these higher dimensional features may under utilize persistent homology's analysis potential.
In this project, we explore different methodologies to find efficient options that could solve this issue. 
We specifically aim to characterize the computational performance (run time) and limits of persistent homology calculations between Vietoris-Rips complexes in the \CRANpkg{TDAstats} and \CRANpkg{TDA} R packages.
We also explore the differences in computational performance between Vietoris-Rips and alpha complexes in R to assess which datasets are most appropriate for each algorithm.

\section{Mathematics of Persistent Homology}
This section summarizes the mathematics behind generating simplicial complexes on point clouds in the workflow of persistent homology. 
An n-dimensional simplex is the convex hull of n+1 vertices.
More intuitively, n-dimensional simplex is the simplest n-dimensional object (e.g. a 1 simplex is a line, a 2-simplex is a triangle, 3-simplex is a tetrahedron, etc.).
These simplices can be glued together on a common subsimplices to form a simplicial complex (e.g. two triangles sharing a common side).
In a simplicial complex, certain features will arise that can be characterized by dimension number (Betti number): 0-dimensional features refer to connected components, 1-dimensional features refer to holes, 2-dimensional features refer to cavities, etc. \cite{phom-survey}

There are several different methods to construct a simplicial complex on a given point cloud S, but this paper focuses on the Vietoris-Rips and alpha complexes. 
The Vietoris-Rips complex is perhaps the most common method for constructing a simplicial complex under persistent homology \cite{Rips-Complex}.
In a point cloud of k points, a distance parameter, $\delta$, can be used to draw a circle of diameter $\delta$ around every single point in S.
If the distance parameter is non-zero, then some of the resulting circles may intersect.
If they intersect, a line is drawn to connect the points (which represent the centers of the growing circles).
This group of points and lines form a simplicial complex.
For each distance parameter, $\delta$, there will be some simplicial complex associated with it.
As $\delta$ increases, different topological features may appear, persist, then disappear once $\delta$ has reached a threshold.
Eventually, once $\delta$ reaches the maximum euclidean distance between any pair of points in the point cloud, a convex hull will form around all k points creating a (k-1)-dimensional simplex.
At this stage, all features should have disappeared.
A three column matrix can be created recording the Betti number of a certain feature, the distance, $\delta$, at which that feature appeared, and the $\delta$ at which that feature disappeared.
This matrix characterizes the persistent homology of that point cloud. 

\begin{figure}
  \centering
  \includegraphics[height=2.5in]{../Figures/Final_Figures/Intro_Rips.png}
  \caption{Basic Visualization of the Vietoris-Rips Complex. For a given parameter, $\delta$, $\delta$ diameter circles are drawn around each point. If two circles intersect, a point is drawn between their centers. As $\delta$ continues to grow, more circles intersect filling out the simplicial complex. Features on the simplicial complex appear and die as $\delta$ increases. These features' dimensions, birth, and death are recorded in an n x 3 matrix. Eventually, the full convex hull is drawn ending the "filtration" process.}
\end{figure}

Alpha complexes provide another method to generate simplicial complexes on the point cloud S.
Alpha complexes are closely linked with Voronoi diagrams and Delaunay triangulations.
The Voronoi diagram gives each point in S a cell such that each every point in the cell is closest to that point in S.
The nerve of a Voronoi diagram is equivalent to the Delaunay Triangulation\cite{alpha-complex}.
Alpha complexes are simplicial complexes that are subsets of the Delaunay Triangulation.
The parameter, $\alpha$, can describe the radius of a ball of each point in the point cloud S much like $\delta$ describes the diameter of a circle in the Vietoris-Rips complex.
An Alpha complex at radius $\alpha$ is formed through connecting centers of intersecting regions formed by intersecting the union of $\alpha$ radius balls and the Voronoi diagram. 
Eventually, once $\alpha$ is large enough, the full Delaunay Triangulation is formed.
In between these stages, the birth and death of features at certain values of $\alpha$ can be captured in a three column persistent homology matrix much like the Vietoris-Rips complex.

In both methods, the boundary matrix records all simplicial complexes for a given parameter value. 
From this matrix, the persistent homology matrix is calculated. 
The size of the boundary matrix can describe the memory complexity on the RAM for persistent homology calculations. 
We compare this memory complexity between alpha and Vietoris-Rips complexes for this project. 

\begin{figure}
  \centering
  \includegraphics[height=1.5in]{../Figures/Final_Figures/Intro_Alpha.png}
  \caption{Basic visualization of the Alpha complex. For a given $\alpha$, $\alpha$ radius balls are drawn around each point, and the union is taken. Then an intersection between this union of $\alpha$ balls and the Vornoi diagram is taken. A connecting segment is drawn between points in adjacent voronoi cells once the $\alpha$ ball "fills" out the Voronoi diagram. As $\alpha$ continues to grow, more circles fill out the Voronoi cells. Eventually, once $\alpha$ is large enough, the Delaunay Triangulation is formed.}
\end{figure}

\section{Methods}
<!--An exclusively R (v3.6.2) code pipeline was built for this project \citep{Rlang,ihaka1996}.-->
We use \CRANpkg{readr} v1.3.1 to read rectangular data \citep{readr}, \CRANpkg{ggplot2} v3.2.1 \citep{ggplot2}, \CRANpkg{scatterplot3d} v0.3-41 \citep{scatterplot3d}, \CRANpkg{recexcavAAR} v0.3.0 \citep{recexcavAAR}, and \CRANpkg{magick} v2.2 \citep{magick} to visualize data, \CRANpkg{bench} v1.0.4 to collect benchmark data \citep{bench}, \CRANpkg{TDA} v1.6.9 \citep{TDA} and \CRANpkg{TDAstats} v0.4.1 \citep{TDAstats} to calculate persistent homology of Vietoris-Rips and alpha simplicial complices, and \CRANpkg{pryr} v0.1.4 for calculations involving R objects \citep{pryr}.
Runtime calculations were averaged over 10 iterations and are visualized as mean $\pm$ SD.
Datasets were generated by sampling functions in base R to generate points uniformly distributed over circles (dimension = 2), spheres (dimension = 3), filled squares (dimension = 2), filled cubes (dimension = 3, 4), and tori (dimension = 3).
The number of points per point cloud varied from 25 to 500 along intervals of 25 points, which were empiric limits chosen after considering available computational resources.
For consistency between software libraries, the minimum and maximum simplicial complex radii were predetermined for each point cloud and provided as parameters to the \CRANpkg{TDA} and \CRANpkg{TDAstats} R packages.
Within the \CRANpkg{TDA} package, benchmark data was collected for the GUDHI \citep{gudhi} and Dionysus \citep{Dionysus} libraries; within the \CRANpkg{TDAstats} package, benchmark data was collected for the Ripser \citep{Ripser} library.
As alpha complex calculation was only implemented in GUDHI, alpha complex benchmark data was naturally only collected for the single library.
Measuring memory usage proved challenging since all the libraries calculating persistent homology were implemented in either C++ or Java and then wrapped in R as part of a CRAN package.
Thus, memory burden was indirectly measured by using boundary matrix size as a proxy.
Given that Ripser optimizes computation of persistent homology by avoiding calculation of a boundary matrix, memory use benchmarks are not provided for Ripser and, consequently, \CRANpkg{TDAstats}.

Benchmark data was collected twice - once on a local machine and once on a remote computing node, each of which featured 16 GB random access memory.
Both datasets were compared for consistency and are publicly available at the repository linked below.
Data from the remote computing node is visualized in this report.
The larger point clouds required more than 16 GB of RAM to calculate persistent homology using a subset of the libraries; attempts to compute results resulted in runtime errors, and the corresponding output is missing from the corresponding figures and tables.
Fully reproducible code for all numerical results and figures can be found at https://github.com/eashwarsoma/TDA-benchmark.
This GitHub repository also contains instructions for generating the Supplement referenced in this report's results.
Video explanations of TDA concepts and reproducing all results in this report can be found at https://tinyurl.com/TDABench.

\section{Results}

Computing persistent homology of a canonical torus grants quick insight into efficiency of each library (Figure \ref{fig:tor}).
Dionysus exhibits the longest average runtime, and, although Ripser and GUDHI have similar runtimes for smaller point clouds, as the number of points increases Ripser eventually has a significant lead.
Next, we compare library performance with multiple canonical datasets to ensure that the noted pattern generalizes.

\begin{figure}
  \centering
  \includegraphics[height=2.5in]{../Figures/Final_Figures/fig1.png}
  \caption{
    \textbf{Calculating persistent homology of a torus with three TDA libraries.}
    Average runtime (mean $\pm$ SD, $n=10$ iterations per data point) for each TDA library (denoted by color) is plotted against point cloud size.
    Homological features up to 2 dimensions were calculated.
    Time complexity follows a power law for all three libraries (see GitHub repo for regression details).
    Although the libraries have similar runtimes for smaller point clouds, Dionysus has a clear disadvantage when the number of points exceeds 100.
    When the number of points exceeds 200, Ripser has a clear advantage over GUDHI, which maintains its advantage over Dionysus.
  }
\label{fig:tor}
\end{figure}

Tori do not trivially generalize to other dimensions, but circles do.
Benchmarking on a circular point cloud permits confirmation of the pattern in Figure \ref{fig:tor} while also revealing how the libraries compare as dataset dimension increases.
Figure \ref{fig:cir} exhibits the resulting data for a 2-dimensional circle (left panel), 3-dimensional sphere (center panel), and 4-dimensional hypersphere (right panel).
When the dataset dimension equals 2, GUDHI practically matches Ripser's performance in outpacing Dionysus.
However, in the case of the 3-dimensional sphere, the pattern visualized in Figure \ref{fig:tor} for the 3-dimensional torus is again present.
By the 4th dimension, the gap between Ripser and GUDHI widens.
Of note, missing points for larger datasets in Figure \ref{fig:cir} are not plotted if and only if calculating persistent homology caused an error due to insufficient RAM.
Thus, for the hypersphere, Ripser was able to calculate persistent homology for a dataset with approximately 3 times as many points as Dionysus and over 2 times as many as GUDHI.
Interestingly, all curves plotted in Figure \ref{fig:cir} grow polynomially with respect to the number of points (see Supplement for regression details).

\begin{widefigure}
  \centering
  \includegraphics[height=2in]{../Figures/Final_Figures/fig2.png}
  \caption{
    \textbf{Calculating persistent homology of round point clouds of varying dimensions with three TDA libraries.}
    Average runtime (mean $\pm$ SD, $n=10$ iterations per data point) for each TDA library (denoted by color) is plotted against point cloud size and faceted by data dimension.
    Left panel compares library performance for a 2-dimensional circular point cloud; center panel for a 3-dimensional spherical point cloud; and right panel for a 4-dimensional hyperspherical point cloud.
    Maximum feature dimensions (one less than data dimension) were calculated in each case.
  }
\label{fig:cir}
\end{widefigure}

Large data and feature dimensionality often restricts persistent homology calculations to small point clouds due to computational limits.
When calculating persistent homology on a high-dimensional point cloud, as Vietoris-Rips feature dimension increases, there is a corresponding increase in runtime (Figure \ref{fig:box}).
Dionysus is clearly outmatched by GUDHI and Ripser as feature dimension increases, with the difference being clearest for larger point clouds; by feature dimension 5, Ripser outpaces GUDHI as well (Figure \ref{fig:box}).
It is unclear whether runtime for each library grows polynomially or exponentially (see Supplement for regression details).

\begin{widefigure}
  \centering
  \includegraphics[height=2in]{../Figures/Final_Figures/fig3.png}
  \caption{
    \textbf{Comparison of Vietoris-Rips complex persistent homology calculation as a function of feature dimension.}
    Average runtime (mean $\pm$ SD, $n=10$ iterations per data point) for various point cloud sizes (denoted by color) is plotted against calculated feature dimension and faceted by TDA libary.
    Persistent homology was calculated on a uniformly distributed random sample of points contained within a 1 unit, 8-dimensional cube.
    Computational limitations of calculating persistent homology for a large number of feature dimensions restricted point clouds to relatively small sizes.}
\label{fig:box}
\end{widefigure}

Even with a constant feature dimension, the underlying data dimension could play a role in runtime of persistent homology calculation.
Figure \ref{fig:ann} compares handling of this issue by the Vietoris-Rips complex and the alpha complex.
Since GUDHI is the only library implementing functionality with an alpha complex, we compare its implementations of the Vietoris-Rips and alpha complices.
Due to computational limitations, an alpha complex could not be calculated for any point clouds with data dimension exceeding 3.
Two notable aspects of Figure \ref{fig:ann} stand out.
First, the alpha complex calculation clearly runs faster than the Vietoris-Rips complex calculation, a trend that becomes clearer as point cloud size increases.
Second, although the Vietoris-Rips complex calculation runtime appears to be independent of underlying data dimension, alpha complex calculation is dependent on it.
Figure \ref{fig:ann} shows a subtle difference between data dimensions 2 and 3 as point cloud size increases.
Although unconcerning for a data dimension up to 3, failure to run any alpha complex calculations with a data dimension of 4 could be cause for concern.

\begin{figure}
  \centering
  \includegraphics[height=2in]{../Figures/Final_Figures/fig4.png}
  \caption{
    \textbf{Comparing persistent homology calculation between Vietoris-Rips and alpha complices.}
    Average runtime (mean $\pm$ SD, $n=10$ iterations per data point) for various data dimensions (denoted by color) are plotted against point cloud size and faceted by type of simplicial complex.
    Maximum of feature dimension was kept constant at 1.
    Alpha complex runtimes are linear, in contrast to polynomial Vietoris-Rips runtimes (see Supplement for regression details).}
\label{fig:ann}
\end{figure}

Vietoris-Rips and alpha complices differ not only in runtime, but also in memory usage.
GUDHI conveniently allows measurement of the simplicial complex boundary matrix, a reasonable proxy for total memory usage in calculation of persistent homology.
Since Ripser and Dionysus do not have similar capabilities, they are excluded from memory benchmarks.
Vietoris-Rips complices show rapid growth in object size as point cloud size increases; in contrast, alpha complices consistently maintain low, linearly-growing memory use (Figure \ref{fig:mem1}).
The growth pattern differences mirror findings for runtime growth (Figure \ref{fig:ann}).
Interestingly, different factors determine memory usage in the two types of simplicial complex.
Whereas memory use in calculation of a Vietoris-Rips complex is dependent on point cloud size and feature dimension, memory use for an analogous calculation with an alpha complex is also dependent on the structure of the point cloud itself (Figure \ref{fig:mem2}).
Within the limited set of tested point cloud structures, the sphere requires the least memory.
Table \ref{tbl:limit} lists the maximum point cloud size for which persistent homology calculations could be completed for each library.

<!--BELONGS IN DISCUSSION
This is predicted by Vietoris-Rips theoretical exponential complexity and Alpha complex's theoretical polynomial complexity.-->

\begin{figure}
  \centering
  \includegraphics[height=2.5in]{../Figures/Final_Figures/fig5a.png}
  \caption{
    \textbf{Comparing memory usage of persistent homology calculation using a Vietoris-Rips versus an alpha complex.}
    Mean boundary matrix size, a proxy for memory usage, plotted against point cloud size varying by point cloud structure (facet) and simplicial complex type (color, shape).
    Data dimension and feature dimension were held constant at 3 and 2, respectively.
    Point cloud structures for which memory usage was calculated were 3-dimensional annulus (top-left), 3-dimensional sphere (top-right), torus (bottom-left), and 3-dimensional cube (bottom-right).
    Similar to runtime results, alpha complex calculation showed linear growth and Vietoris-Rips complex calculation showed polynomial growth (see Supplement for regression details).}
\label{fig:mem1}
\end{figure}

\begin{widefigure}
  \centering
  \includegraphics[height=2.5in]{../Figures/Final_Figures/fig5t.png}
  \caption{
    \textbf{Factors affecting boundary matrix size in Vietoris-Rips and alpha complices.}
    Mean boundary matrix size plotted against point cloud size varying by point cloud structure (right, faceted), simplicial complex type (left, right), and feature dimension (color).
    Whereas the boundary matrix for a Vietoris-Rips complex (left) is independent of point cloud structure, the same is not true for an alpha complex (right, faceted).
    For the Vietoris-Rips complex, the decreasing number of data points plotted for successive feature dimensions reflects the computational requirements of increasing point cloud size.}
\label{fig:mem2}
\end{widefigure}

\begin{table}
\centering
\small
\begin{tabular}{|c|c|c|c|c|}
\hline
Feature & Ripser & Dionysus & GUDHI Rips & GUDHI Alpha \\
Dimension & Point Cloud Limit & Point Cloud Limit & Point Cloud Limit & Point Cloud Limit\\
\hline
1 & Not Reached & Not Reached & Not Reached & Not Reached \\ 
2 & Not Reached & 200 points & 280 points & Not Reached \\ 
3 & 300 points & 100 points & 125 points & Could Not Compute \\
4 & 100 points & 50 points & 75 points & Could Not Compute \\ 
\hline
\end{tabular}
\caption{During the benchmarking, certain libraries were not able to calculate persistent homology for sufficiently complex point clouds. 
Limiting factors were point cloud number and feature dimension calculation. 
For Vietoris-Rips complices, Ripser had the best performing capacity among the three libraries. 
Alpha complexes were not computable for any point cloud greater than 3 dimensions, so dimensional features 3 and higher could not be computed.}
\label{tbl:limit}
\end{table}

In real life scenarios, practitioners likely care most about comparative performance of the fastest Vietoris-Rips complex library and the fastest alpha complex library.
Figure \ref{fig:fin} illustrates this comparison, showing that for 3-dimensional point clouds, GUDHI's alpha complex library outpaces Ripser's Vietoris-Rips functionality.

\section{Discussion}
As persistent homology calculations continue to become a more popular tool to analyze complex multidimensional data, it will be important to understand from a computational perspective which method to use. 
In this paper, we examined two forms of persistent homology complexes: Vietoris-Rips and alpha complexes. 
Both algorithms describe topological features through the generation of simplicial complexes. 
The advantage in saving computational time by choosing a particular algorithm depends on point cloud characteristics.

Figure \ref{fig:fin} shows that at high point cloud sizes, GUDHIâ€™s alpha complex outperforms Ripser. 
Theoretically, alpha complexes gain polynomial complexity as the number of points increases whereas Vietoris-Rips complexes gain exponentially \citep{roadmap}.
Specifically, alpha complexes are $O(n^{d/2})$ and Vietoris-Rips complexes are $O(2^n)$ where $n$ is the number of points on a point cloud and $d$ is the dimensions on the point cloud. 
For the conditions in our paper, Vietoris-Rips and alpha complexes both performed better than their theoretical maximums.
Vietoris-Rips complex calculations consistently had a polynomial growth for both runtime and boundary matrix size while alpha complexes had linear growth.

\begin{figure}
  \centering
  \includegraphics[height=2.5in]{../Figures/Final_Figures/fig6.png}
  \caption{
    \textbf{Runtime comparison of persistent homology calculation between Ripser's Vietoris-Rips and GUDHI's alpha complex functionality.}
    Average runtime (mean $\pm$ SD, $n=10$ iterations per data point) for various 3-dimensional point cloud structures (facet) plotted against point cloud size for each library (color).
    Benchmarking was conducted on an annulus (top-left), a sphere (top-right), a torus (bottom-left), and a cube (bottom-right).
    Data was not collected for data dimensions greater than 3 due to computational limitations of calculating alpha complices.}
\label{fig:fin}
\end{figure}

Based on the theoretical complexity and our results, alpha complexes are superior for point clouds with 3 or fewer dimensions.
This advantage becomes especially clear at high number of points.
However, without sufficient computational resources, alpha complexes were not usable for point cloud dimensions greater than 3.
If a point cloud has more than 3 dimensions, then it could undergo pre-processing with dimension reduction before using alpha complexes.
However, if data dimension cannot be reduced without significant information loss, then Vietoris-Rips complexes should be used.
Among the tested libraries, Ripser (wrapped by \CRANpkg{TDAstats}) has the fastest calculation time. 
GUDHI and Dionysus (wrapped by \CRANpkg{TDA}) significantly fall behind as feature dimension and number of points increase. 
GUDHI and Dionysus, however, do have the option of returning the boundary matrix, which Ripser does not store for the sake of optimization.
While we did not measure Ripser's boundary matrix object size, Ripser's C++ code (outside its implementation in R) demonstrates memory advantages ~\citep{Ripser}

While Vietoris-Rips complexes can handle high-dimensional data well, calculation still significantly slows down when looking for higher dimension features. 
Boundary matrix size rapidly increases and can overwhelm available random access memory even for small numbers of points (e.g. 100 points when looking for 4-dimensional features). 
Looking for high-dimensional features in a large, high-dimensional point clouds remains a challenge. 
Methods to calculate persistent homology do exist for other simplicial complexes, such as the Delaunay complex and the Witness complex, but, to our knowledge, they are not currently implemented in CRAN packages.
Future challenges would be creating and implementing algorithms that reduce the computational complexity of higher dimensional topological feature calculations for R.

<!--Include somewhere: 

differences are b/n implementations (practical) not necessarily mathematical structures (theory), so results can change as implementations change (whether b/n libraries or b/n complices)

Ripser memory not measured here b/c R, but refer to Bauer Ripser memory measurements.

Vietoris-Rips complex memory more predictable, but alpha complex memory generally better (but what about Ripser?).

Thoughts on why sphere alpha uses less memory than 3-d annulus alpha

Weigh limitations and benefits of each library/complex type based on Table 1
-->

<!--PUT AS TEXT INSTEAD
\begin{figure}
  \centering
  \includegraphics[height=2.5in]{decision.png}
    \caption{Basic decision chart for choosing TDA library based on dataset.}
\label{decision}
\end{figure}-->

\section{Acknowledgments}
Emily Dolson, PhD for assistance with using a high-performance computing node for data collection.

\bibliography{tdabench}